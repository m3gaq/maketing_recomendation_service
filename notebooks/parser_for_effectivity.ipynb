{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "В данном ноутбуке мы парсим данные с сайта spymetrics. Эти данные представляют из собой: \n",
        "1. Посещаемость сайтов \n",
        "2. Показатель отказов (то, сколько людей заходят на одну страницу и выходят) \n",
        "3. Средняя продолжительность визита сайта \n",
        "\n",
        "Изначально мы выбрали примено 25 каналов, которые по нашему мнению являются наиболее привлекательными рекламными площадками. И хотим по этим 25 сайтам получить необходимую статистику для оценки эффективности каналов. Для парсинга сайтов мы используем библиотеку BeautifulSoup и регулярные выражения. "
      ],
      "metadata": {
        "id": "i5a-XmLac_3B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "9yjhCmKUzu5I"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import ast\n",
        "import pandas as pd\n",
        "pd.options.display.float_format = '{:.5f}'.format\n",
        "\n",
        "import plotly.express as px\n",
        "import datetime\n",
        "from requests_html import HTMLSession\n",
        "from bs4 import BeautifulSoup\n",
        "from datetime import datetime\n",
        "import plotly.express as px"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "YqWlA5Biz2KW"
      },
      "outputs": [],
      "source": [
        "def parse_reject_time(website):\n",
        "    \"\"\"\n",
        "    Возвращает показатель отказов, среднюю продолжительность визита на сайте\n",
        "    ----------\n",
        "    website: str\n",
        "        Название сайта, который мы хотим проанализировать на эффективность.\n",
        "    Returns\n",
        "    -------\n",
        "    reject_final: float\n",
        "    time_final_new: float\n",
        "        Показатель отказов\n",
        "        Средняя продолжительность отказов\n",
        "    \"\"\"\n",
        "\n",
        "  root_url = \"https://spymetrics.ru/ru/website/\" \n",
        "  full_url = root_url + website\n",
        "\n",
        "  # создаем объект HTML сессии \n",
        "  session = HTMLSession()\n",
        "\n",
        "  # Используем этот оюъект для соединения с нужной WEB-страницей\n",
        "  html= session.get(full_url).text\n",
        "\n",
        "  soup = BeautifulSoup(html, \"html.parser\")\n",
        "  \n",
        "  # Находим все теги, которые нам необходимы, чтобы сократить \n",
        "  list_js_scripts = soup.find_all(\"tbody\")\n",
        "\n",
        "\n",
        "  js_script_str = None\n",
        "  for js_script in list_js_scripts:\n",
        "      if \"jQuery('#webcompareform')\" in str(js_script):\n",
        "          js_script_str = js_script.contents[0]\n",
        "\n",
        "   # используем регулярные выражения для приближения к показателю отказов\n",
        "  index_1= [match.start() for match in re.finditer(\"Показатель отказов\", str(list_js_scripts[0]))][0]\n",
        "  reject_1 = str(list_js_scripts[0])[index_1:]\n",
        "\n",
        "  \n",
        "  index_2 = [match.start() for match in re.finditer(\"text-right\", reject_1)]\n",
        "  index_end = [match.end() for match in re.finditer(\"</td>\",reject_1)][1]\n",
        "  a_new = reject_1[index_2[0]:index_end][12:]\n",
        "  a_end = a_new[:-6]\n",
        "\n",
        "  # получаем итоговый показатель отказов\n",
        "  reject_final = float(a_end)\n",
        "  index_1_time= [match.start() for match in re.finditer(\"Время на сайте\", str(list_js_scripts[0]))][0]\n",
        "  time_1 = str(list_js_scripts[0])[index_1_time:]\n",
        "  index_2_time = [match.start() for match in re.finditer(\"text-right\", time_1)]\n",
        "  index_end_time = [match.end() for match in re.finditer(\"</td>\",time_1)][1]\n",
        "  a_new_time = time_1[index_2_time[0]:index_end_time][12:]\n",
        "\n",
        "  # получаем время типа string, необходимо преобразоват в количество секунд\n",
        "  time_final = a_new_time[:-5]\n",
        "  import datetime \n",
        "  time1= datetime.time(0,0,0)\n",
        "  from datetime import datetime, date\n",
        "  time_object = datetime.strptime(time_final, '%H:%M:%S').time()\n",
        "  time_final_new = datetime.combine(date.today(), time_object) - datetime.combine(date.today(), time1)\n",
        "  return reject_final, time_final_new"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "d2FiV8VmQ9JT"
      },
      "outputs": [],
      "source": [
        "def visits_data(website):\n",
        "   \"\"\"\n",
        "    Рассчитывает количество визитов на сайте \n",
        "    ----------\n",
        "    website: str\n",
        "        Название сайта, который мы хотим проанализировать на эффективность.\n",
        "    Returns\n",
        "    -------\n",
        "    d1['chart']['title']: string\n",
        "    d1['series'][1]['data']: list\n",
        "        Возвращает строку \"Визитов\".\n",
        "        Возвращает список количества визитов ежемесячно.\n",
        "    \"\"\"\n",
        "\n",
        "    root_url = \"https://spymetrics.ru/ru/website/\" \n",
        "    full_url = root_url + website\n",
        "\n",
        "    # создаем HTML сессию\n",
        "    session = HTMLSession()\n",
        "\n",
        "    # Используем объект сессии для соединения с вебсайтом\n",
        "    html= session.get(full_url).text\n",
        "    soup = BeautifulSoup(html, \"html.parser\")\n",
        "    list_js_scripts = soup.find_all(\"script\", type=\"text/javascript\")\n",
        "    for js_script in list_js_scripts:\n",
        "      if \"jQuery('#webcompareform')\" in str(js_script):\n",
        "          js_script_str_ = js_script.contents[0]\n",
        "    \n",
        "    js_script_str = re.sub(\"Highcharts.Map\", \"Highcharts.Chart\", js_script_str_)\n",
        "    \n",
        "    # Находим индексы Highcharts.Chart\n",
        "    lst_1 = [match.start() for match in re.finditer(\"new Highcharts.Chart\", js_script_str)][1:]\n",
        "    lst_2 = [match.end() for match in re.finditer(\"new Highcharts.Chart\", js_script_str)]\n",
        "    \n",
        "    # Пары индексов, находящихся между lst_1 и lst_2\n",
        "    lst_tuples = list(zip(lst_2, lst_1))\n",
        "    lst_lists = [list(elem) for elem in lst_tuples]\n",
        "    \n",
        "    # Избавляемся от мусора\n",
        "    for t in lst_lists:\n",
        "        t[0] = t[0] + 1\n",
        "        t[1] = t[1] - 30\n",
        "        \n",
        "    # Извлекаем содержимое между Highcharts/Chart\n",
        "    d1_str = js_script_str[lst_lists[0][0]:lst_lists[0][1]]\n",
        "    d1_str = re.sub('false', \"False\", d1_str)\n",
        "    d1_str = re.sub('null', '\"\"', d1_str)\n",
        "    re.sub(\"\\\\\\\\\",'\"', d1_str) ### careful, assignment may be needed!!!\n",
        "    \n",
        "    # Превращаем в словарь\n",
        "    d1 = ast.literal_eval(d1_str)\n",
        "    \n",
        "    return d1['chart']['title'], d1['series'][1]['data']"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "В последующей функции мы рассчитываем эффективность. Эффективность рассчитывается по формуле: \n",
        "$$ Эффективность = \\frac{\\mbox{Средняя  продолжительность} \\cdot \\mbox{Количество визитов за последний месяц}}{\\mbox{Показатель отказов}}$$"
      ],
      "metadata": {
        "id": "IS3xBRavdMMf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "4D1kWrgi3pDb"
      },
      "outputs": [],
      "source": [
        "def plt_efficiency(file):\n",
        "  \"\"\"\n",
        "    Строит графики по эффективности каналов в зависимости от кластера\n",
        "    ----------\n",
        "    file: str\n",
        "        Название файла с результатами кластеризации\n",
        "    Returns\n",
        "    -------\n",
        "    Два графика, потсроенных на одинковых данных, но в разном формате \n",
        "    \"\"\"\n",
        "  df_top5 = pd.read_csv(file)\n",
        "\n",
        "  # создаем список с возможными сайтами\n",
        "  websites = ['vk.ru', 'telegram.me', 'ok.ru', 'rbc.ru', 'vc.ru',  'forbes.ru', 'habr.com', 'knife.media', 'novayagazeta.ru', 'youtube.ru', \n",
        "  'ozon.ru', 'rutube.ru', 'avito.ru', 'cian.ru', 'youla.ru', 'wildberries.ru', 'wasd.tv', 'goodgame.ru', 'likee.video', 'otzovik.com', \n",
        "  'ivi.ru', 'kinopoisk.ru', '2gis.ru', 'fl.ru', 'netology.ru']\n",
        "  efficiency = []\n",
        "\n",
        "  # итерируемся по вебсайтам и рассчитывем среднюю продолжительность на сайте и визиты\n",
        "  for i in websites:\n",
        "    print(i)\n",
        "    a = parse_reject_time(i)[1].total_seconds()\n",
        "    b = parse_reject_time(i)[0]\n",
        "    t = visits_data(i)[1][-1]\n",
        "    efficiency.append(a * t/b)\n",
        "\n",
        "  # создаем датафрейсм с сайтом и соответсвующей эффективностью \n",
        "  d = {'site': websites, 'efficiency': efficiency}\n",
        "  df_media = pd.DataFrame(data=d)\n",
        "  df_top_merged = df_top5.merge(df_media,on='site',how='left')\n",
        "  df_top_merged['relative_efficiency'] = df_top_merged['efficiency']/df_top_merged['total_diff']\n",
        "  print(df_top_merged)\n",
        "  print(df_top_merged['efficiency'])\n",
        "  print(df_top_merged['total_diff'])\n",
        "  print(df_top_merged['cluster'])\n",
        "  print(df_top_merged['site'])\n",
        "  plt_topscat = px.scatter(df_top_merged,'efficiency','total_diff','cluster','site', title='Эффективность каналов на основе анализа ЦА банка и канала', labels={'x': 'Эффективность', 'y': 'Степень различия ЦА банка и канала'})\n",
        "  plt_topbar = px.bar(df_top_merged,'site',['total_diff','efficiency','relative_efficiency'],facet_col='cluster',opacity=0.7, title='Анализ эффективности каналов', labels={'x': 'Сайт', 'y': 'Метрика'})\n",
        "  return plt_topscat, plt_topbar"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "parser_for_effectivity.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Содержание",
      "title_sidebar": "Contents",
      "toc_cell": true,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}